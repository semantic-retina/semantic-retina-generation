"""
This script combines the FGADR and IDRiD datasets and splits them into train/test
subsets. CSV files containing file paths are saved to `data/train.csv` and
`data/test.csv`. Ensure that you have run the pre-processing scripts first.
"""

from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd
import torch
import torchvision.transforms as T
from PIL import Image
from sklearn.model_selection import train_test_split
from torch import nn
from torchvision.transforms import InterpolationMode
from tqdm import tqdm

from src.data.common import get_label_semantics
from src.models.resnet.label import load_label_model
from src.models.resnet.retina import load_retina_model
from src.options.split import get_args


def make_fgadr(
    original_dir: str, processed_dir: str, denylist_path: str
) -> pd.DataFrame:
    """
    :param original_dir: Path to the original FGADR directory. We use this to get the
    original images (since they not edited by the preprocessing script).
    :param processed_dir: Path to the preprocessed images, generated by the
    `preprocess_datasets.py` script.
    :param exclude_grader_1: Whether to exclude images graded by "grader 1" from the
    resulting paths. These images are coarsely annotated (inconsistent with other
    images), and can be excluded to avoid annotator bias.

    :returns: A pandas DataFrame containing paths to files in the FGADR dataset.
    """
    fgadr_original_path = Path(original_dir)
    fgadr_image_path = fgadr_original_path / "Original_Images"
    fgadr_label_path = Path(processed_dir) / "label"
    fgadr_inst_path = Path(processed_dir) / "inst"
    fgadr_transform_path = Path(processed_dir) / "transformed"
    fgadr_csv_path = fgadr_original_path / "DR_Seg_Grading_Label.csv"

    fgadr_df = pd.read_csv(fgadr_csv_path, header=None, names=["File", "Grade"])

    if denylist_path:
        denylist = pd.read_csv(denylist_path)
        # Set dummy value to preserve the int type of Grade.
        denylist["Grade"] = 0
        fgadr_df = pd.concat([fgadr_df, denylist]).drop_duplicates(
            keep=False, subset="File"
        )

    fgadr_df = make_absolute_paths(
        fgadr_df,
        fgadr_image_path,
        fgadr_label_path,
        fgadr_inst_path,
        fgadr_transform_path,
    )

    fgadr_df["Source"] = "FGADR"

    return fgadr_df


def make_idrid(
    processed_dir: str,
    grade_inference_strategy: Optional[str],
    grade_inference_model: Optional[str],
) -> pd.DataFrame:
    """
    :param processed_dir: Path to the preprocessed images, generated by the
    `preprocess_datasets.py` script.
    :param predict_grades: Whether or not to use a model to predict the DR grades of
    these images.

    :returns: A pandas DataFrame containing paths to files in the IDRiD dataset.
    """
    idrid_root_path = Path(processed_dir)

    idrid_image_path = idrid_root_path / "img"
    idrid_label_path = idrid_root_path / "label"
    idrid_inst_path = idrid_root_path / "inst"
    idrid_transform_path = idrid_root_path / "transformed"

    idrid_files = [f.name for f in idrid_image_path.glob("**/*")]
    idrid_files.sort()

    idrid_df = pd.DataFrame(idrid_files, columns=["File"])

    idrid_df = make_absolute_paths(
        idrid_df,
        idrid_image_path,
        idrid_label_path,
        idrid_inst_path,
        idrid_transform_path,
    )

    # Predict labels.
    if grade_inference_strategy == "label":
        model_path = Path(
            f"results/resnet/{grade_inference_model}/checkpoints/model_latest.pth"
        )
        model = load_label_model(model_path)
        noisy_grades = predict_from_label(model, idrid_df)
    elif grade_inference_strategy == "image":
        model_path = Path(
            f"results/resnet/{grade_inference_model}/checkpoints/model_latest.pth"
        )
        model = load_retina_model(model_path)
        noisy_grades = predict_from_image(model, idrid_df)
    elif grade_inference_strategy == "random":
        # Numpy's randint has an exclusive end point.
        noisy_grades = np.random.randint(0, 5, size=len(idrid_df))
    else:
        raise ValueError("Invalid grade inference strategy")

    idrid_df["Grade"] = noisy_grades

    idrid_df["Source"] = "IDRiD"

    return idrid_df


def make_diaretdb1(
    processed_dir: str,
    grade_inference_strategy: Optional[str],
    grade_inference_model: Optional[str],
) -> pd.DataFrame:
    """
    :param processed_dir: Path to the preprocessed images, generated by the
    `preprocess_datasets.py` script.
    :param predict_grades: Whether or not to use a model to predict the DR grades of
    these images.

    :returns: A pandas DataFrame containing paths to files in the DIARETDB1 dataset.
    """
    # TODO(sonjoonho): Reduce duplication between this and IDRiD.
    diaretdb1_root_path = Path(processed_dir)

    diaretdb1_img_path = diaretdb1_root_path / "img"
    diaretdb1_label_path = diaretdb1_root_path / "label"
    diaretdb1_inst_path = diaretdb1_root_path / "inst"
    diaretdb1_transform_path = diaretdb1_root_path / "transformed"

    diaretdb1_files = [f.name for f in diaretdb1_img_path.glob("**/*")]
    diaretdb1_files.sort()

    diaretdb1_df = pd.DataFrame(diaretdb1_files, columns=["File"])

    diaretdb1_df = make_absolute_paths(
        diaretdb1_df,
        diaretdb1_img_path,
        diaretdb1_label_path,
        diaretdb1_inst_path,
        diaretdb1_transform_path,
    )

    # Predict labels.
    if grade_inference_strategy == "label":
        model_path = Path(
            f"results/resnet/{grade_inference_model}/checkpoints/model_latest.pth"
        )
        model = load_label_model(model_path)
        noisy_grades = predict_from_label(model, diaretdb1_df)
    elif grade_inference_strategy == "image":
        model_path = Path(
            f"results/resnet/{grade_inference_model}/checkpoints/model_latest.pth"
        )
        model = load_retina_model(model_path)
        noisy_grades = predict_from_image(model, diaretdb1_df)
    elif grade_inference_strategy == "random":
        # Numpy's randint has an exclusive end point.
        noisy_grades = np.random.randint(0, 5, size=len(diaretdb1_df))
    else:
        raise ValueError("Invalid grade inference strategy")

    diaretdb1_df["Grade"] = noisy_grades

    diaretdb1_df["Source"] = "DIARETDB1"

    return diaretdb1_df


def make_eophtha(
    processed_dir: str,
    grade_inference_strategy: Optional[str],
    grade_inference_model: Optional[str],
) -> pd.DataFrame:
    """
    :param processed_dir: Path to the preprocessed images, generated by the
    `preprocess_datasets.py` script.
    :param predict_grades: Whether or not to use a model to predict the DR grades of
    these images.

    :returns: A pandas DataFrame containing paths to files in the DIARETDB1 dataset.
    """
    # TODO(sonjoonho): Reduce duplication between this and IDRiD.
    eophtha_root_path = Path(processed_dir)

    eophtha_img_path = eophtha_root_path / "img"
    eophtha_label_path = eophtha_root_path / "label"
    eophtha_inst_path = eophtha_root_path / "inst"
    eophtha_transform_path = eophtha_root_path / "transformed"

    eophtha_files = [f.name for f in eophtha_img_path.glob("**/*")]
    eophtha_files.sort()

    eophtha_df = pd.DataFrame(eophtha_files, columns=["File"])

    eophtha_df = make_absolute_paths(
        eophtha_df,
        eophtha_img_path,
        eophtha_label_path,
        eophtha_inst_path,
        eophtha_transform_path,
    )

    # Predict labels.
    if grade_inference_strategy == "label":
        model_path = Path(
            f"results/resnet/{grade_inference_model}/checkpoints/model_latest.pth"
        )
        model = load_label_model(model_path)
        noisy_grades = predict_from_label(model, eophtha_df)
    elif grade_inference_strategy == "image":
        model_path = Path(
            f"results/resnet/{grade_inference_model}/checkpoints/model_latest.pth"
        )
        model = load_retina_model(model_path)
        noisy_grades = predict_from_image(model, eophtha_df)
    elif grade_inference_strategy == "random":
        # Numpy's randint has an exclusive end point.
        noisy_grades = np.random.randint(0, 5, size=len(eophtha_df))
    else:
        raise ValueError("Invalid grade inference strategy")

    eophtha_df["Grade"] = noisy_grades

    eophtha_df["Source"] = "e-ophtha"

    return eophtha_df


def predict_from_label(model: nn.Module, df: pd.DataFrame) -> np.ndarray:
    """Predicts labels dataset using the specified model."""
    img_size = 512
    transform = T.Compose(
        [T.Resize(img_size, interpolation=InterpolationMode.NEAREST), T.ToTensor()]
    )

    predictions = np.empty(len(df), dtype=int)
    for i, row in tqdm(df.iterrows()):
        label = Image.open(row["Label"])
        label = transform(label).unsqueeze(0)
        label = get_label_semantics(label)
        pred = model(label)
        pred = torch.argmax(pred)
        predictions[i] = pred.item()

    return predictions


def predict_from_image(model: nn.Module, df: pd.DataFrame) -> np.ndarray:
    """Predicts labels using the specified model."""
    img_size = 512
    transform = T.Compose([T.Resize(img_size), T.ToTensor()])
    rotation = T.RandomRotation(360)

    predictions = np.empty(len(df), dtype=int)
    for i, row in tqdm(df.iterrows()):
        image = Image.open(row["Transformed"])
        image = transform(image).unsqueeze(0) * 255.0
        tta_runs = 5
        tta_preds = torch.empty((tta_runs, 5), dtype=float).cuda()
        for run in range(tta_runs):
            transformed_image = rotation(image)
            with torch.no_grad():
                output = model(transformed_image)
            tta_preds[run, :] = output
        tta_preds = torch.mean(tta_preds, dim=0)
        pred = torch.argmax(tta_preds)
        predictions[i] = int(pred.item())

    return predictions


def make_absolute_paths(
    df: pd.DataFrame,
    image_path: Path,
    label_path: Path,
    inst_path: Path,
    transform_path: Path,
) -> pd.DataFrame:
    """Converts filenames to absolute paths using the specified root paths."""
    df["Image"] = str(image_path) + "/" + df["File"].astype(str)
    df["Label"] = str(label_path) + "/" + df["File"].astype(str)
    df["Instance"] = str(inst_path) + "/" + df["File"].astype(str)
    df["Transformed"] = str(transform_path) + "/" + df["File"].astype(str)

    return df


def main():
    opt = get_args()

    data_path = Path("data")
    data_path.mkdir(parents=True, exist_ok=True)

    fgadr_df = make_fgadr(
        opt.fgadr_original_dir,
        opt.fgadr_processed_dir,
        opt.denylist,
    )

    idrid_df = make_idrid(
        opt.idrid_processed_dir, opt.grade_inference_strategy, opt.grade_inference_model
    )

    # diaretdb1_df = make_diaretdb1(
    #     opt.diaretdb1_processed_dir,
    #     opt.grade_inference_strategy,
    #     opt.grade_inference_model,
    # )

    eophtha_df = make_eophtha(
        opt.eophtha_processed_dir,
        opt.grade_inference_strategy,
        opt.grade_inference_model,
    )

    combined_df = pd.concat((fgadr_df, idrid_df, eophtha_df))

    # Remove redundant "File" column.
    combined_df = combined_df.drop("File", axis=1)

    combined_train, combined_test = train_test_split(
        combined_df, train_size=opt.train_size, random_state=opt.seed
    )

    print(f"FGADR : {len(fgadr_df)}")
    print(f"IDRiD: {len(idrid_df)}")
    # print(f"DIARETDB1: {len(diaretdb1_df)}")
    print(f"e-ophtha: {len(eophtha_df)}")

    print(f"Train: {len(combined_train)}")
    print(f"Test: {len(combined_test)}")

    combined_df.to_csv(data_path / "all.csv")
    combined_train.to_csv(data_path / "train.csv")
    combined_test.to_csv(data_path / "test.csv")


if __name__ == "__main__":
    main()
