"""
This script combines the FGADR and IDRiD datasets and splits them into train/test
subsets. CSV files containing file paths are saved to `data/train.csv` and
`data/test.csv`. Ensure that you have run the pre-processing scripts first.
"""

from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd
import torch
import torchvision.transforms as T
from PIL import Image
from sklearn.model_selection import train_test_split
from torch import nn
from torchvision.transforms import InterpolationMode
from tqdm import tqdm

from src.data.common import get_label_semantics
from src.models.resnet.label import load_label_model
from src.models.resnet.retina import load_retina_model
from src.options.split import get_args


def make_fgadr(
    original_dir: str, processed_dir: str, denylist_path: str
) -> pd.DataFrame:
    """
    :param original_dir: Path to the original FGADR directory. We use this to get the
    original images (since they not edited by the preprocessing script).
    :param processed_dir: Path to the preprocessed images, generated by the
    `preprocess_datasets.py` script.
    :param exclude_grader_1: Whether to exclude images graded by "grader 1" from the
    resulting paths. These images are coarsely annotated (inconsistent with other
    images), and can be excluded to avoid annotator bias.

    :returns: A pandas DataFrame containing paths to files in the FGADR dataset.
    """
    fgadr_original_path = Path(original_dir)
    fgadr_image_path = fgadr_original_path / "Original_Images"
    fgadr_label_path = Path(processed_dir) / "label"
    fgadr_inst_path = Path(processed_dir) / "inst"
    fgadr_transform_path = Path(processed_dir) / "transformed"
    fgadr_csv_path = fgadr_original_path / "DR_Seg_Grading_Label.csv"

    fgadr_df = pd.read_csv(fgadr_csv_path, header=None, names=["File", "Grade"])

    if denylist_path:
        denylist = pd.read_csv(denylist_path)
        # Set dummy value to preserve the int type of Grade.
        denylist["Grade"] = 0
        fgadr_df = pd.concat([fgadr_df, denylist]).drop_duplicates(
            keep=False, subset="File"
        )

    fgadr_df = make_absolute_paths(
        fgadr_df,
        fgadr_image_path,
        fgadr_label_path,
        fgadr_inst_path,
        fgadr_transform_path,
    )

    fgadr_df["Source"] = "FGADR"

    return fgadr_df


def make_fgadr_grade(fgadr_df: pd.DataFrame) -> pd.DataFrame:
    return fgadr_df[["Image", "Transformed", "Grade", "Source"]]


def make_idrid_grade(original_dir: str, processed_dir: str) -> pd.DataFrame:
    original_path = Path(original_dir)
    idrid_root_path = Path(processed_dir)

    idrid_image_path = idrid_root_path / "img"
    idrid_transform_path = idrid_root_path / "transformed"

    idrid_df_1 = pd.read_csv(
        original_path
        / "2. Groundtruths"
        / "a. IDRiD_Disease Grading_Training Labels.csv"
    )
    idrid_df_2 = pd.read_csv(
        original_path
        / "2. Groundtruths"
        / "b. IDRiD_Disease Grading_Testing Labels.csv"
    )

    idrid_df = pd.concat((idrid_df_1, idrid_df_2))
    idrid_df = idrid_df[["Image name", "Retinopathy grade"]]
    idrid_df = idrid_df.rename(
        columns={"Image name": "File", "Retinopathy grade": "Grade"}
    )

    idrid_df["File"] = idrid_df["File"].astype(str) + ".png"
    idrid_df["Image"] = str(idrid_image_path) + "/" + idrid_df["File"].astype(str)
    idrid_df["Transformed"] = (
        str(idrid_transform_path) + "/" + idrid_df["File"].astype(str)
    )

    idrid_df["Source"] = "IDRiD"

    return idrid_df


def make_idrid(
    processed_dir: str,
    grade_inference_strategy: Optional[str],
    grade_inference_model: Optional[str],
) -> pd.DataFrame:
    """
    :param processed_dir: Path to the preprocessed images, generated by the
    `preprocess_datasets.py` script.
    :param predict_grades: Whether or not to use a model to predict the DR grades of
    these images.

    :returns: A pandas DataFrame containing paths to files in the IDRiD dataset.
    """
    idrid_root_path = Path(processed_dir)

    idrid_image_path = idrid_root_path / "img"
    idrid_label_path = idrid_root_path / "label"
    idrid_inst_path = idrid_root_path / "inst"
    idrid_transform_path = idrid_root_path / "transformed"

    idrid_files = [f.name for f in idrid_image_path.glob("**/*")]
    idrid_files.sort()

    idrid_df = pd.DataFrame(idrid_files, columns=["File"])

    idrid_df = make_absolute_paths(
        idrid_df,
        idrid_image_path,
        idrid_label_path,
        idrid_inst_path,
        idrid_transform_path,
    )

    # Predict labels.
    if grade_inference_strategy == "label":
        model_path = Path(
            f"results/resnet/{grade_inference_model}/checkpoints/model_latest.pth"
        )
        model = load_label_model(model_path)
        noisy_grades = predict_from_label(model, idrid_df)
    elif grade_inference_strategy == "image":
        model_path = Path(
            f"results/resnet/{grade_inference_model}/checkpoints/model_latest.pth"
        )
        model = load_retina_model(model_path)
        noisy_grades = predict_from_image(model, idrid_df)
    elif grade_inference_strategy == "random":
        # Numpy's randint has an exclusive end point.
        noisy_grades = np.random.randint(0, 5, size=len(idrid_df))
    else:
        raise ValueError("Invalid grade inference strategy")

    idrid_df["Grade"] = noisy_grades

    idrid_df["Source"] = "IDRiD"

    return idrid_df


def make_diaretdb1(
    processed_dir: str,
    grade_inference_strategy: Optional[str],
    grade_inference_model: Optional[str],
) -> pd.DataFrame:
    """
    :param processed_dir: Path to the preprocessed images, generated by the
    `preprocess_datasets.py` script.
    :param predict_grades: Whether or not to use a model to predict the DR grades of
    these images.

    :returns: A pandas DataFrame containing paths to files in the DIARETDB1 dataset.
    """
    # TODO(sonjoonho): Reduce duplication between this and IDRiD.
    diaretdb1_root_path = Path(processed_dir)

    diaretdb1_img_path = diaretdb1_root_path / "img"
    diaretdb1_label_path = diaretdb1_root_path / "label"
    diaretdb1_inst_path = diaretdb1_root_path / "inst"
    diaretdb1_transform_path = diaretdb1_root_path / "transformed"

    diaretdb1_files = [f.name for f in diaretdb1_img_path.glob("**/*")]
    diaretdb1_files.sort()

    diaretdb1_df = pd.DataFrame(diaretdb1_files, columns=["File"])

    diaretdb1_df = make_absolute_paths(
        diaretdb1_df,
        diaretdb1_img_path,
        diaretdb1_label_path,
        diaretdb1_inst_path,
        diaretdb1_transform_path,
    )

    # Predict labels.
    if grade_inference_strategy == "label":
        model_path = Path(
            f"results/resnet/{grade_inference_model}/checkpoints/model_latest.pth"
        )
        model = load_label_model(model_path)
        noisy_grades = predict_from_label(model, diaretdb1_df)
    elif grade_inference_strategy == "image":
        model_path = Path(
            f"results/resnet/{grade_inference_model}/checkpoints/model_latest.pth"
        )
        model = load_retina_model(model_path)
        noisy_grades = predict_from_image(model, diaretdb1_df)
    elif grade_inference_strategy == "random":
        # Numpy's randint has an exclusive end point.
        noisy_grades = np.random.randint(0, 5, size=len(diaretdb1_df))
    else:
        raise ValueError("Invalid grade inference strategy")

    diaretdb1_df["Grade"] = noisy_grades

    diaretdb1_df["Source"] = "DIARETDB1"

    return diaretdb1_df


def make_eophtha(
    processed_dir: str,
    grade_inference_strategy: Optional[str],
    grade_inference_model: Optional[str],
) -> pd.DataFrame:
    """
    :param processed_dir: Path to the preprocessed images, generated by the
    `preprocess_datasets.py` script.
    :param predict_grades: Whether or not to use a model to predict the DR grades of
    these images.

    :returns: A pandas DataFrame containing paths to files in the DIARETDB1 dataset.
    """
    # TODO(sonjoonho): Reduce duplication between this and IDRiD.
    eophtha_root_path = Path(processed_dir)

    eophtha_img_path = eophtha_root_path / "img"
    eophtha_label_path = eophtha_root_path / "label"
    eophtha_inst_path = eophtha_root_path / "inst"
    eophtha_transform_path = eophtha_root_path / "transformed"

    eophtha_files = [f.name for f in eophtha_img_path.glob("**/*")]
    eophtha_files.sort()

    eophtha_df = pd.DataFrame(eophtha_files, columns=["File"])

    eophtha_df = make_absolute_paths(
        eophtha_df,
        eophtha_img_path,
        eophtha_label_path,
        eophtha_inst_path,
        eophtha_transform_path,
    )

    # Predict labels.
    if grade_inference_strategy == "label":
        model_path = Path(
            f"results/resnet/{grade_inference_model}/checkpoints/model_latest.pth"
        )
        model = load_label_model(model_path)
        noisy_grades = predict_from_label(model, eophtha_df)
    elif grade_inference_strategy == "image":
        model_path = Path(
            f"results/resnet/{grade_inference_model}/checkpoints/model_latest.pth"
        )
        model = load_retina_model(model_path)
        noisy_grades = predict_from_image(model, eophtha_df)
    elif grade_inference_strategy == "random":
        # Numpy's randint has an exclusive end point.
        noisy_grades = np.random.randint(0, 5, size=len(eophtha_df))
    else:
        raise ValueError("Invalid grade inference strategy")

    eophtha_df["Grade"] = noisy_grades

    eophtha_df["Source"] = "e-ophtha"

    return eophtha_df


def predict_from_label(model: nn.Module, df: pd.DataFrame) -> np.ndarray:
    """Predicts labels dataset using the specified model."""
    img_size = 512
    transform = T.Compose(
        [T.Resize(img_size, interpolation=InterpolationMode.NEAREST), T.ToTensor()]
    )

    predictions = np.empty(len(df), dtype=int)
    for i, row in tqdm(df.iterrows(), total=len(df)):
        label = Image.open(row["Label"])
        label = transform(label).unsqueeze(0)
        label = get_label_semantics(label)
        pred = model(label)
        pred = torch.argmax(pred)
        predictions[i] = pred.item()

    return predictions


def predict_from_image(model: nn.Module, df: pd.DataFrame) -> np.ndarray:
    """Predicts labels using the specified model."""
    img_size = 512
    transform = T.Compose([T.Resize(img_size), T.ToTensor()])

    predictions = np.empty(len(df), dtype=int)
    for i, row in tqdm(df.iterrows(), total=len(df)):
        image = Image.open(row["Transformed"])
        image = transform(image).unsqueeze(0) * 255.0
        with torch.no_grad():
            output = model(image)
        pred = torch.argmax(output)
        predictions[i] = int(pred.item())

    return predictions


def make_absolute_paths(
    df: pd.DataFrame,
    image_path: Path,
    label_path: Path,
    inst_path: Path,
    transform_path: Path,
) -> pd.DataFrame:
    """Converts filenames to absolute paths using the specified root paths."""
    df["Image"] = str(image_path) + "/" + df["File"].astype(str)
    df["Label"] = str(label_path) + "/" + df["File"].astype(str)
    df["Instance"] = str(inst_path) + "/" + df["File"].astype(str)
    df["Transformed"] = str(transform_path) + "/" + df["File"].astype(str)

    return df


def get_n_from_source(df):
    return (
        f"    FGADR: {len(df[df['Source'] == 'FGADR'])}"
        f"    IDRiD: {len(df[df['Source'] == 'IDRiD'])}"
        f"    e-ophtha: {len(df[df['Source'] == 'e-ophtha'])}"
    )


def main():
    opt = get_args()

    data_path = Path("data")
    data_path.mkdir(parents=True, exist_ok=True)

    fgadr_df = make_fgadr(
        opt.fgadr_original_dir,
        opt.fgadr_processed_dir,
        opt.denylist,
    )

    idrid_df = make_idrid(
        opt.idrid_processed_dir, opt.grade_inference_strategy, opt.grade_inference_model
    )

    eophtha_df = make_eophtha(
        opt.eophtha_processed_dir,
        opt.grade_inference_strategy,
        opt.grade_inference_model,
    )

    combined_df = pd.concat((fgadr_df, idrid_df, eophtha_df))

    # Remove redundant "File" column.
    combined_df = combined_df.drop("File", axis=1)

    combined_train, combined_test = train_test_split(
        combined_df, train_size=0.8, random_state=opt.seed
    )

    combined_test, combined_val = train_test_split(
        combined_test, train_size=0.5, random_state=opt.seed
    )

    print(f"FGADR : {len(fgadr_df)}")
    print(f"IDRiD: {len(idrid_df)}")
    print(f"e-ophtha: {len(eophtha_df)}")

    print(f"Train: {len(combined_train)}")
    print(get_n_from_source(combined_train))

    print(f"Val: {len(combined_val)}")
    print(get_n_from_source(combined_val))

    print(f"Test: {len(combined_test)}")
    print(get_n_from_source(combined_test))

    combined_df.to_csv(data_path / "all.csv")
    combined_train.to_csv(data_path / "train.csv")
    combined_val.to_csv(data_path / "val.csv")
    combined_test.to_csv(data_path / "test.csv")

    eyepacs_path = Path("/vol/biomedic/users/aa16914/shared/data/retina/eyepacs")
    eyepacs_out_path = data_path / "eyepacs"
    eyepacs_out_path.mkdir(parents=True, exist_ok=True)

    eyepacs_path_1 = eyepacs_path / "train_all_df.csv"
    eyepacs_path_2 = eyepacs_path / "test_private_df.csv"
    eyepacs_path_3 = eyepacs_path / "test_public_df.csv"

    eyepacs_df_1 = pd.read_csv(eyepacs_path_1)
    eyepacs_df_2 = pd.read_csv(eyepacs_path_2)
    eyepacs_df_3 = pd.read_csv(eyepacs_path_3)

    eyepacs_df = pd.concat((eyepacs_df_1, eyepacs_df_2, eyepacs_df_3))

    eyepacs_train, eyepacs_test = train_test_split(
        eyepacs_df, train_size=0.8, random_state=opt.seed
    )

    eyepacs_train.to_csv(eyepacs_out_path / "train.csv")
    eyepacs_test.to_csv(eyepacs_out_path / "test.csv")

    grade_out_path = data_path / "grade"
    grade_out_path.mkdir(parents=True, exist_ok=True)

    idrid_grade_df = make_idrid_grade(
        opt.idrid_grade_original_dir, opt.idrid_grade_processed_dir
    )

    fgadr_train_grade_df = make_fgadr_grade(
        combined_train[combined_train["Source"] == "FGADR"]
    )
    fgadr_val_grade_df = make_fgadr_grade(
        combined_val[combined_val["Source"] == "FGADR"]
    )
    fgadr_test_grade_df = make_fgadr_grade(
        combined_test[combined_test["Source"] == "FGADR"]
    )

    idrid_grade_train, idrid_grade_test = train_test_split(
        idrid_grade_df, train_size=0.8, random_state=opt.seed
    )

    idrid_grade_test, idrid_grade_val = train_test_split(
        idrid_grade_test, train_size=0.5, random_state=opt.seed
    )

    grade_train = pd.concat((idrid_grade_train, fgadr_train_grade_df))
    grade_val = pd.concat((idrid_grade_val, fgadr_val_grade_df))
    grade_test = pd.concat((idrid_grade_test, fgadr_test_grade_df))
    grade_df = pd.concat((grade_train, grade_val, grade_test))

    grade_df.to_csv(grade_out_path / "all.csv")
    grade_train.to_csv(grade_out_path / "train.csv")
    grade_val.to_csv(grade_out_path / "val.csv")
    grade_test.to_csv(grade_out_path / "test.csv")

    print(f"FGADR (Grade) : {len(fgadr_df)}")
    print(f"IDRiD (Grade): {len(idrid_grade_df)}")

    print(f"Train: {len(grade_train)}")
    print(get_n_from_source(grade_train))

    print(f"Val: {len(grade_val)}")
    print(get_n_from_source(grade_val))

    print(f"Test: {len(grade_test)}")
    print(get_n_from_source(grade_test))


if __name__ == "__main__":
    main()
